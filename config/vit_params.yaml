
model_params:
  block_size: 288    # can fit the max of 247 amino acids + CLS token + PAD tokens
                     # and be reshaped into a (48,48) single-channel tensor of 1's and 0's
                     # (48,48) needed to allow for 4x4 patches fed into the ViT model
  mask_prob: 0.0

  image_shape: [48, 48] # 48x48 pixel images
  patch_dim: 4          # 4x4 pixel patches
  num_heads: 8 
  num_layers: 6
  dim: 128  
  dropout: 0.3

  accelerator : 'mps' # cpu, gpu, mps(macbook M2 chip)
  devices: 1
  batch_size: 512 
  num_workers: 10
  grad_norm_clip : 1.0
  num_epochs : 1000
  log_dir : './lightning_logs/vit_model/cleaned-2/'
  train_data_path: None #'/Users/markthompson/Documents/dev/a-alphaBio-homework/data/q_cleaned_3_train_set.csv'
  test_data_path:  None #'/Users/markthompson/Documents/dev/a-alphaBio-homework/data/q_cleaned_3_val_set.csv'

  inference_data_path:  '/Users/markthompson/Documents/dev/a-alphaBio-homework/data/q_cleaned_2_val_set.csv'
  # inference_data_path: '/Users/markthompson/Documents/dev/a-alphaBio-homework/data/alphaseq_data_hold_out.csv'

  checkpoint_name: '/Users/markthompson/Documents/dev/a-alphaBio-homework/lightning_logs/vit_model/cleaned-2/trained/checkpoints/epoch=836-step=18400.ckpt' 
  learning_rate : 0.0001
  lr_gamma: 0.9990     # for exponential learning rate decay
  betas : [0.9, 0.95]

  checkpoint_every_n_train_steps : 100
  save_top_k : 4
  monitor: 'val_loss'
  mode: 'min'
  log_every_nsteps: 10

  inference_results_folder: './inference_results/vit/cleaned-2/'

  seed : 3407

