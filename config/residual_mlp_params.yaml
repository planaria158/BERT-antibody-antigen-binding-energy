
model_params:
  block_size: 248    # max of 247 amino acids + CLS token (which hopefully is vestigal for this model)
  seq_flip_prob: 0.0 #0.1 # regularization: probability of flipping the sequence back-to-front
  mask_prob: 0.0
  mlp_dropout : 0.2
  accelerator : 'mps' # cpu, gpu, mps(macbook M2 chip)
  devices: 1
  batch_size: 512
  num_workers: 5
  grad_norm_clip : 1.0
  num_epochs : 10000
  log_dir : './lightning_logs/residual_mlp_model/cleaned-3/'
  train_data_path: '/Users/markthompson/Documents/dev/a-alphaBio-homework/data/q_cleaned_3_train_set.csv'
  test_data_path:  '/Users/markthompson/Documents/dev/a-alphaBio-homework/data/q_cleaned_3_val_set.csv'

  inference_data_path: '/Users/markthompson/Documents/dev/a-alphaBio-homework/data/q_cleaned_3_val_set.csv'
  # inference_data_path: '/Users/markthompson/Documents/dev/a-alphaBio-homework/data/alphaseq_data_hold_out.csv'

  checkpoint_name: '/Users/markthompson/Documents/dev/a-alphaBio-homework/lightning_logs/residual_mlp_model/cleaned-3/version_2/checkpoints/epoch=7152-step=121600.ckpt' 

  learning_rate : 0.0001
  lr_gamma: 0.9990     # for exponential learning rate decay
  betas : [0.9, 0.95]

  checkpoint_every_n_train_steps : 100
  save_top_k : 1
  monitor: 'val_loss'
  mode: 'min'
  log_every_nsteps: 10

  inference_results_folder: './inference_results/residual_mlp/cleaned-3/'
  
  seed : 3407

