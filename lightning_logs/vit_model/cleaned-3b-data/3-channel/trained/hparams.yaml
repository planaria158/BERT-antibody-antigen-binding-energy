config:
  accelerator: gpu
  batch_size: 384
  betas:
  - 0.9
  - 0.95
  checkpoint_every_n_train_steps: 100
  checkpoint_name: None
  devices: 2
  emb_dropout: 0.15
  grad_norm_clip: 1.0
  inference_results_folder: ../inference_results/vit_model/cleaned-3b-data/3-channel
  learning_rate: 0.001
  log_dir: ../lightning_logs/vit_model/cleaned-3b-data/3-channel
  log_every_nsteps: 10
  lr_gamma: 0.9995
  mlp_dropout: 0.3
  mode: min
  monitor: val_loss
  num_epochs: 500
  num_workers: 10
  save_top_k: 5
  seq_flip_prob: 0.0
  seq_mask_prob: 0.05
  sequence_regularize: true
  test_results_folder: ../test_results/vit_model/cleaned-3b-data/3-channel
  tform_dropout: 0.15
  train_data_path: ../data/q_cleaned_3b_train_set.csv
  val_data_path: ../data/q_cleaned_3b_val_set.csv
model_config:
  block_size: 242
  dim_head: 64
  emb_dim: 256
  image_channels: 3
  image_shape:
  - 44
  - 44
  num_heads: 8
  num_layers: 6
  patch_dim: 4
  vocab_size]: 24
