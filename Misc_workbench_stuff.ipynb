{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a-AlphaBio homework \n",
    "### misc. futzing about.... prob messy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "# import libraries\n",
    "import numpy as np\n",
    "import pickle as pk\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "import yaml\n",
    "import sys\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "# import sys\n",
    "# sys.path.append(\"../\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiply two 1d tensors to get a 2d tensor\n",
    "def outer_product(t1, t2):\n",
    "    return t1[:, None] * t2[None, :]\n",
    "#     return torch.einsum('i,j->ij', t1, t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(5)\n",
    "y = torch.randn(5)\n",
    "\n",
    "# vx = x - torch.mean(x)\n",
    "# vy = y - torch.mean(y)\n",
    "# c = outer_product(vx, vy)\n",
    "# c = c/math.sqrt(torch.norm(vx)*torch.norm(vy))\n",
    "\n",
    "# create a 2x5 matrix c from x and y\n",
    "c = torch.stack([x, y])\n",
    "\n",
    "print(c)\n",
    "\n",
    "p = torch.corrcoef(c)\n",
    "print(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(a)\n",
    "a = a.view(1, -1)   #a.unsqueeze(0)\n",
    "# print(a.shape)\n",
    "b = b.view(-1, 1)  #.unsqueeze(-1)\n",
    "# print(b.shape)\n",
    "\n",
    "# print(a)\n",
    "# print(b)\n",
    "\n",
    "c = a*b\n",
    "\n",
    "torch.corrcoef(c)\n",
    "\n",
    "# torch.einsum('i,j->ij', a, b)\n",
    "\n",
    "# outer_product(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'QVQLVQSGVEVKKPGASVKVSCKASGYTFTNYYWVRQAPGQGLEWMGGINPSNGGTNFNEKFKNRVTLTTDSSTTTAYMELKSLQFDDTAVYYCARRDYRFDMGFDYWYWGQGTTVTV'\n",
    "l = 'SSGGGGSGGGGSGGGGSE'\n",
    "b = 'IVLTQSPATLSLSPGERATLSCRASKGVSTSGYSYLHWYQQKPGQAPRLLIYLASYLESGVPARFSGSGSGTDFTLTISSLEPEDFAVYYCQHSRDLPLTFGGGTKVEIK'\n",
    "\n",
    "print(len(a), len(l), len(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from torch import tensor, nn\n",
    "\n",
    "def softmax(x):\n",
    "    return np.exp(x) / np.exp(x).sum(axis=1, keepdims=True)\n",
    "\n",
    "labels = [0, 2, 1, 3]\n",
    "logits =  np.array([\n",
    "    [3.5, -3.45, 0.23, 1.25],\n",
    "    [-2.14, 0.54, 2.67, -5.23],\n",
    "    [-1.34, 5.01, -1.54, -1.17],\n",
    "    [ -2.98, -1.37, 1.54,5.23]\n",
    "])\n",
    "probs = softmax(logits)\n",
    "print(probs)\n",
    "log_probs = np.log(softmax(logits))\n",
    "print('\\n', log_probs)\n",
    "\n",
    "nll = -(log_probs[range(len(labels)), labels])\n",
    "nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.tensor([0, 2, 1, 3])\n",
    "logits =  torch.tensor(np.array([\n",
    "    [3.5, -3.45, 0.23, 1.25],\n",
    "    [-2.14, 0.54, 2.67, -5.23],\n",
    "    [-1.34, 5.01, -1.54, -1.17],\n",
    "    [ -2.98, -1.37, 1.54,5.23]\n",
    "]))\n",
    "\n",
    "output = F.cross_entropy(logits, labels, reduction='none')\n",
    "print(output.shape)\n",
    "loss = torch.mean(output) #output.sum() / mask.shape[0]\n",
    "print(loss)\n",
    "print()\n",
    "loss = output.sum() / labels.shape[0]\n",
    "print(loss)\n",
    "print()\n",
    "\n",
    "lossfn = torch.nn.CrossEntropyLoss()\n",
    "output = lossfn(logits, labels)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# loss = torch.nn.CrossEntropyLoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "print('input shape:', input.shape)\n",
    "print('target shape:', target.shape)\n",
    "print(input)\n",
    "print(target)\n",
    "\n",
    "output = F.cross_entropy(input, target, reduction='none')\n",
    "print(output.shape)\n",
    "loss = torch.mean(output) #output.sum() / mask.shape[0]\n",
    "print(loss)\n",
    "print()\n",
    "\n",
    "lossfn = torch.nn.CrossEntropyLoss()\n",
    "output = lossfn(input, target)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "output = loss(input, target)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(4, 4)\n",
    "print(x.size())\n",
    "y = x.view(16)\n",
    "print(y.size())\n",
    "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
    "print(z.size())\n",
    "a = x.view(-1)\n",
    "print(a.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = torch.tensor([0.1])\n",
    "p = torch.tensor([1])\n",
    "\n",
    "ce = - torch.sum(p * torch.log(q))\n",
    "print(ce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'TNYYMYWVRQAPGQGLEWMGGINPSNGGTNFNEKFKNRVTLTTDSSTTTAYMELKSLQFDDTAVYYCARRDYRFDMGFD'\n",
    "print(len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the config\n",
    "config_path = './config/tform_params.yaml'\n",
    "with open(config_path, 'r') as file:\n",
    "    try:\n",
    "        config = yaml.safe_load(file)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n",
    "\n",
    "model_config = config['model_params']\n",
    "train_config = config['train_params']    \n",
    "\n",
    "print(model_config)\n",
    "print(train_config)\n",
    "pl.seed_everything(config['seed'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class scFv_diy_pretrain_Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class for the paired sequences for pretraining the model\n",
    "    The data consists of paired heavy and light chain sequences\n",
    "    They are concatenated with a \"standard\" scFv linker sequence\n",
    "    Hence the \"DIY\" in the name\n",
    "    50% of the time, the heavy and light chains are swapped\n",
    "\n",
    "    The dataset is a csv file with the following columns:\n",
    "    - sequence_alignment_aa_heavy: amino acid sequence of the heavy chain\n",
    "    - sequence_alignment_aa_light: amino acid sequence of the light chain\n",
    "\n",
    "    The dataset is used for pretraining the model with the following task:\n",
    "    Masked language model training\n",
    "        The masked language model training sequence with a small percentage of the amino acids masked\n",
    "        sequence will look something like:           [CLS, aa, aa, MASK, aa, MASK, aa, ...PAD,..PAD]\n",
    "        corresponding mask will look something like: [0,   0,   0,   aa,  0,   aa, 0, ...0, 0]\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, config, block_size, csv_file_path, skiprows=0, inference=False, regularize=False):  \n",
    "        super().__init__()\n",
    "        print('DIY scFv sequences created by this dataset class')\n",
    "        self.config = config\n",
    "        self.block_size = block_size\n",
    "        self.inference = inference\n",
    "        self.regularize = regularize # sequence flipping etc...\n",
    "        assert config['train_type'] in ['mask_lang_model', 'regression'], 'train_type must be either \"mask_lang_model\" or \"regression\"'\n",
    "        self.train_type = config['train_type']\n",
    "\n",
    "        print('reading the data from:', csv_file_path)\n",
    "        self.df = pd.read_csv(csv_file_path, skiprows=skiprows)\n",
    "        \n",
    "        # 20 amino acids + special tokens (CLS, X, PAD, MASK, SEP) \n",
    "        self.chars = ['CLS', 'A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', \n",
    "                      'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y', 'X', 'MASK', 'PAD', 'SEP']\n",
    "        self.first_aa_idx = 1\n",
    "        self.last_aa_idx = len(self.chars) - 4\n",
    "        print('vocabulary:', self.chars)\n",
    "        data_size, vocab_size = self.df.shape[0], len(self.chars)\n",
    "        print('data has %d rows, %d vocab size' % (data_size, vocab_size))\n",
    "\n",
    "        # encoding and decoding residues\n",
    "        self.stoi = { ch:i for i,ch in enumerate(self.chars) }\n",
    "        self.itos = { i:ch for i,ch in enumerate(self.chars) }\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        self.linker = 'SSGGGGSGGGGSGGGGSE' # fixed linker sequnce\n",
    "        print('Using fixed linker sequence:', self.linker)\n",
    "\n",
    "    #-------------------------------------------------------\n",
    "    # Create the mask for masked language model training\n",
    "    # and the corresponding modified dix sequence\n",
    "    #\n",
    "    # if cls = True, prepend a CLS token, else don't\n",
    "    #-------------------------------------------------------\n",
    "    def create_mask(self, dix, cls=True):\n",
    "\n",
    "        # prepend the CLS token to the sequence\n",
    "        if cls:\n",
    "          dix = torch.cat((torch.tensor([self.stoi['CLS']], dtype=torch.long), dix))\n",
    "          \n",
    "        mask = torch.zeros_like(dix)\n",
    "\n",
    "        # training will be masked language model\n",
    "        if self.train_type == 'mask_lang_model':\n",
    "\n",
    "            # get number of tokens to mask\n",
    "            n_pred = max(1, int(round(self.block_size * self.config['mask_prob'])))\n",
    "\n",
    "            # indices of the tokens that will be masked (a random permutation of n_pred of the tokens)\n",
    "            masked_idx = torch.randperm(len(dix)-1, dtype=torch.long)[:n_pred]\n",
    "            masked_idx += 1  # so we never mask the CLS token\n",
    "            mask = torch.zeros_like(dix)\n",
    "\n",
    "            # copy the actual tokens to be masked, to the mask\n",
    "            mask[masked_idx] = dix[masked_idx]\n",
    "            # And replace all masked tokens with the MASK token\n",
    "            dix[masked_idx] = self.stoi['MASK']\n",
    "\n",
    "        assert(dix.shape[0] == mask.shape[0]), 'dix and mask shape is not equal'\n",
    "        return dix, mask\n",
    "\n",
    "\n",
    "    def get_vocab_size(self):\n",
    "        return self.vocab_size\n",
    "\n",
    "    def get_block_size(self):\n",
    "        return self.block_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0] \n",
    "\n",
    "    #-------------------------------------------------------\n",
    "    # Get the sequence, and mask data for the given index\n",
    "    #-------------------------------------------------------\n",
    "    def __getitem__(self, idx):\n",
    "        seq1 = self.df.loc[idx, 'sequence_alignment_aa_heavy']\n",
    "        seq2 = self.df.loc[idx, 'sequence_alignment_aa_light']\n",
    "\n",
    "        assert isinstance(seq1, str), 'seq1 is not a string'\n",
    "        assert isinstance(seq2, str), 'seq2 is not a string'\n",
    "\n",
    "        # flip the order of heavy, light chains 50% of the time\n",
    "        if random.random() > 0.5:\n",
    "            seq1, seq2 = seq2, seq1\n",
    "\n",
    "        chunk = seq1 + self.linker + seq2\n",
    "        print('chunk shape:', len(chunk))\n",
    "\n",
    "        # hardwired for now\n",
    "        Kd = 0\n",
    "        name = 'none'\n",
    "\n",
    "        # trim if necessary\n",
    "        if len(chunk) >= (self.block_size-1):  # '-1' is to accomodate the CLS tokens below\n",
    "            chunk = chunk[0:self.block_size-1]\n",
    "            print('trimmed chunk shape:', len(chunk))\n",
    "\n",
    "        # encode the string chunk\n",
    "        dix = torch.tensor([self.stoi[s] for s in chunk], dtype=torch.long)\n",
    "        print('dix:', dix)\n",
    "\n",
    "        # create the mask for the masked language model training\n",
    "        # and the corresponding modified dix sequence\n",
    "        dix, mask = self.create_mask(dix, cls=True)\n",
    "\n",
    "        # Append with PAD tokens if necessary\n",
    "        if dix.shape[0] < self.block_size:\n",
    "            dix = torch.cat((dix, torch.tensor([self.stoi['PAD']] * (self.block_size - len(dix)), dtype=torch.long)))\n",
    "            mask = torch.cat((mask, torch.tensor([0] * (self.block_size - len(mask)), dtype=torch.long)))\n",
    "\n",
    "        assert(dix.shape[0] == self.block_size), 'dix shape is not equal to block_size'\n",
    "        assert(mask.shape[0] == self.block_size), 'mask shape is not equal to block_size'\n",
    "\n",
    "        return dix, mask, torch.tensor([Kd], dtype=torch.float32), name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = './data/oas_2/paired/paired_1_set.csv'\n",
    "dataset = scFv_diy_pretrain_Dataset(train_config, model_config['block_size'], csv_file_path, regularize=train_config['sequence_regularize'])\n",
    "\n",
    "x, mask, kd, name = dataset.__getitem__(0)\n",
    "print('x shape:', x.shape, 'mask shape:', mask.shape, ', kd:', kd, ', name:', name)\n",
    "\n",
    "print('x[-10:]:', x[-10:])\n",
    "print()\n",
    "\n",
    "print(x)\n",
    "print()\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(dataset, batch_size=256) #config['batch_size'])\n",
    "it = iter(train_loader)\n",
    "x, mask, kd, _ = next(it)\n",
    "print('x.dtype:', x.dtype, ', x.shape:', x.shape, ', mask.shape:', mask.shape, ', kd.shape:', kd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from datasets.scFv_dataset import scFv_Dataset\n",
    "\n",
    "#--------------------------------------------------------\n",
    "# Simple wrapper Dataset to turn output from the scFv dataset\n",
    "# into a B&W image for use in a CNN model\n",
    "#--------------------------------------------------------\n",
    "class CNN_Dataset_BGR(Dataset):\n",
    "    \"\"\"\n",
    "    Emits 2D B&W images and binding energies\n",
    "    \"\"\"\n",
    "    def __init__(self, config, csv_file_path, transform=None, skiprows=0, inference=False):  \n",
    "        super().__init__()\n",
    "        self.scFv_dataset = scFv_Dataset(config, csv_file_path, skiprows, inference)\n",
    "        self.config = config\n",
    "        self.img_shape = config['image_shape']\n",
    "        self.transform = transform\n",
    "         \n",
    "        chars = self.scFv_dataset.chars\n",
    "        groups= ['none', 'nonpolar', 'nonpolar', 'neg', 'neg', 'nonpolar', 'nonpolar', 'pos', 'nonpolar', 'pos', 'nonpolar', 'nonpolar', 'neg', \n",
    "                'nonpolar', 'neg', 'pos', 'polar', 'polar', 'nonpolar', 'nonpolar', 'polar', 'none', 'none', 'none']\n",
    "        \n",
    "        # for VIT, since the residue encodings are spread over 8-bits, assign encodings to groups that spread across the 8-bits\n",
    "        group_encodings = { 'none'    : int('11001100', base=2), \n",
    "                            'polar'   : int('00110011', base=2),\n",
    "                            'nonpolar': int('01100110', base=2), \n",
    "                            'pos'     : int('01010101', base=2),\n",
    "                            'neg'     : int('10101010', base=2)} \n",
    "        \n",
    "        print('group_encodings:', group_encodings)\n",
    "\n",
    "        # map encoded sequence to groups\n",
    "        self.i_to_grp = {self.scFv_dataset.stoi[ch]:group_encodings[i] for ch,i in zip(chars, groups)} \n",
    "\n",
    "        # The relative mutation frequence for each amino acid position in the scFv sequences over the entire clean_3 dataset\n",
    "        # This fixed-array is 241 elements long. (I clipped off the last 5 residues from the 246 residue sequences for the VIT model)\n",
    "        self.rel_mutation_freq = torch.tensor([ 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "                                                0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "                                                0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "                                                0.0000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.7778,\n",
    "                                                0.9444, 0.9444, 1.0000, 1.0000, 1.0000, 0.9444, 1.0000, 1.0000, 0.8889,\n",
    "                                                0.5556, 0.5000, 0.2222, 0.3333, 0.2778, 0.6111, 0.4444, 0.5556, 1.0000,\n",
    "                                                0.8333, 0.8333, 0.8333, 0.9444, 0.7778, 0.8333, 0.6111, 1.0000, 0.8889,\n",
    "                                                0.3333, 0.9444, 0.8889, 0.1111, 0.3889, 0.9444, 0.2778, 0.9444, 0.8333,\n",
    "                                                0.5000, 1.0000, 1.0000, 1.0000, 0.9444, 0.6111, 0.6111, 0.7778, 0.2778,\n",
    "                                                0.8889, 0.3889, 0.9444, 1.0000, 0.3889, 0.9444, 1.0000, 0.9444, 0.2222,\n",
    "                                                0.7778, 0.5556, 0.8889, 0.2222, 0.7778, 0.6111, 0.6667, 0.8333, 0.8333,\n",
    "                                                1.0000, 1.0000, 0.8889, 0.8333, 0.8333, 0.9444, 0.7222, 0.9444, 0.9444,\n",
    "                                                0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "                                                0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "                                                0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "                                                0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "                                                0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "                                                0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "                                                0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "                                                0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "                                                0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "                                                0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "                                                0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "                                                0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "                                                0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "                                                0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "                                                0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]) \n",
    "        \n",
    "        self.mutation_freq_encoded = self.rel_mutation_freq * 255\n",
    "        self.mutation_freq_encoded = torch.ceil(self.mutation_freq_encoded).to(torch.long)\n",
    "        print('min mutation freq:', torch.min(self.mutation_freq_encoded), 'max mutation freq:', torch.max(self.mutation_freq_encoded))\n",
    "        print('some mutation_freq_encoded values:', self.mutation_freq_encoded[60:70])\n",
    "        \n",
    "    def get_vocab_size(self):\n",
    "        return self.scFv_dataset.vocab_size\n",
    "\n",
    "    def get_block_size(self):\n",
    "        return self.config['block_size']\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.scFv_dataset.__len__()\n",
    "\n",
    "    def _bin(self, x):\n",
    "        return format(x, '08b')\n",
    "\n",
    "    def _encode_channel(self, x, shape):\n",
    "        d = ''.join([self._bin(val) for val in x])\n",
    "        d = [int(x) for x in d] # turn d into a list of integers, one for each bit\n",
    "        t = torch.tensor(d[:(shape[0]*shape[1])], dtype=torch.float32) # this is for shape matrix\n",
    "        t = t.reshape(shape)\n",
    "        return t\n",
    "\n",
    "    \"\"\" Returns image, Kd pairs used for CNN training \"\"\"\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        dix, kd = self.scFv_dataset.__getitem__(idx)\n",
    "\n",
    "        # The residue encoding channel\n",
    "        ch_1 = self._encode_channel(dix, self.img_shape)\n",
    "        print('ch_1:', ch_1.shape, torch.min(ch_1), torch.max(ch_1))\n",
    "\n",
    "        # The residue group encoding channel\n",
    "        dix_grp = torch.tensor([self.i_to_grp[i] for i in dix.numpy().tolist()], dtype=torch.long)\n",
    "        ch_2 = self._encode_channel(dix_grp, self.img_shape)\n",
    "        print('ch_2:', ch_2.shape, torch.min(ch_2), torch.max(ch_2))   \n",
    "\n",
    "        # The mutation frequency channel; anything not an amino acid gets a zero.\n",
    "        ch3_in = torch.zeros_like(dix)\n",
    "        # First aa is always position 1 (0 is a CLS token)\n",
    "        ch3_in[1:len(self.mutation_freq_encoded)+1] = self.mutation_freq_encoded\n",
    "        ch_3 = self._encode_channel(ch3_in, self.img_shape)\n",
    "        print('ch_3:', ch_3.shape, torch.min(ch_3), torch.max(ch_3))   \n",
    "\n",
    "        # stack the 3 channels into a bgr image\n",
    "        bgr_img = torch.stack((ch_1, ch_2, ch_3), dim=0) * 255\n",
    "\n",
    "        if self.transform:\n",
    "            bgr_img = self.transform(bgr_img)\n",
    "            \n",
    "        # Normalize image [-1, 1]\n",
    "        bgr_img = (bgr_img - 127.5)/127.5\n",
    "\n",
    "\n",
    "        return bgr_img, kd, ch_1, ch_2, ch_3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "# from datasets.scFv_dataset import scFv_Dataset as dataset\n",
    "from torchvision.transforms.v2 import Resize, Compose, ToDtype, RandomHorizontalFlip, RandomVerticalFlip \n",
    "\n",
    "# train_transforms = Compose([ToDtype(torch.float32, scale=False),\n",
    "#                             RandomHorizontalFlip(p=0.25),\n",
    "#                             RandomVerticalFlip(p=0.25)])\n",
    "\n",
    "train_data_path = config['train_data_path']  \n",
    "train_dataset = CNN_Dataset_BGR(config, train_data_path) #, train_transforms)\n",
    "print(train_dataset.__len__())\n",
    "config['vocab_size'] = train_dataset.get_vocab_size()\n",
    "print('config[vocab_size]:', config['vocab_size'], ', config[block_size]:', config['block_size'])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, pin_memory=True, batch_size=config['batch_size'], num_workers=config['num_workers'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, kd, ch_1, ch_2, ch_3 = train_dataset.__getitem__(105)\n",
    "print(img.dtype)\n",
    "# change the order of the channels to be (H, W) instead of (C, H, W)\n",
    "rgb_img = img.permute(1, 2, 0)\n",
    "\n",
    "print('img shape:', img.shape, ', kd:', kd)\n",
    "# plt.imshow(rgb_img) #, cmap='gray')\n",
    "\n",
    "plt.imshow(ch_3, cmap='gray')\n",
    "\n",
    "print(torch.min(rgb_img), ', ', torch.max(rgb_img), ', ', torch.mean(rgb_img), ', ', torch.std(rgb_img))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Examine other data that may be added as input channels to Vision Transformer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify the amino acids into their usual groups\n",
    "# polar, nonpolar, positively charged, negatively charged, or none (i.e. CLS, SEP, PAD)\n",
    "#\n",
    "# 20 naturally occuring amino acids in human proteins plus MASK token, \n",
    "# 'X' is a special token for unknown amino acids, and CLS token is for classification, and PAD for padding\n",
    "chars = ['CLS', 'A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y', 'X', 'MASK', 'PAD']\n",
    "groups= ['none', 'nonpolar', 'nonpolar', 'neg', 'neg', 'nonpolar', 'nonpolar', 'pos', 'nonpolar', 'pos', 'nonpolar', 'nonpolar', 'neg', \n",
    "         'nonpolar', 'neg', 'pos', 'polar', 'polar', 'nonpolar', 'nonpolar', 'polar', 'none', 'none', 'none']\n",
    "print('\\nvocabulary:', chars)\n",
    "\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "\n",
    "# for VIT, since the residue encodings are spread over 8-bits, assign encodings to groups that spread across the 8-bits\n",
    "group_encodings = { 'none'    : int('00101000', base=2), \n",
    "                    'polar'   : int('00110011', base=2),\n",
    "                    'nonpolar': int('11001100', base=2), \n",
    "                    'pos'     : int('01010101', base=2),\n",
    "                    'neg'     : int('10101010', base=2)} \n",
    "\n",
    "print('group_encodings:', group_encodings)\n",
    "\n",
    "# maps amino acid to group                     \n",
    "s_to_grp = {ch:group_encodings[i] for ch,i in zip(chars, groups)} \n",
    "# maps encoded residue to group\n",
    "i_to_grp = {stoi[ch]:group_encodings[i] for ch,i in zip(chars, groups)} \n",
    "\n",
    "print('\\ns_to_grp:', s_to_grp)\n",
    "print('\\ni_to_grp:', i_to_grp)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def _bin(x):\n",
    "    return format(x, '08b')\n",
    "\n",
    "def _encode_channel(x, shape=(48,48)):\n",
    "    d = ''.join([_bin(x[i]) for i in x.numpy()])\n",
    "    # turn d into a list of integers, one for each bit\n",
    "    d = [int(x) for x in d]    \n",
    "    t = torch.tensor(d[:(shape[0]*shape[1])], dtype=torch.float32) # this is for 46,46 matrix\n",
    "    t = t.reshape(shape)\n",
    "    # t = t.unsqueeze(0) # add channel dimension\n",
    "    return t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a heat-map for the variability of each position in the sequence?\n",
    "# That somehow changes with each sequence?\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "avm-dvm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
