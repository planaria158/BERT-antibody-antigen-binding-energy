{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a-AlphaBio homework \n",
    "### Run inference with some of the trained models\n",
    "### Mark Thompson\n",
    "### Started April 29, 2024 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "# import libraries\n",
    "import numpy as np\n",
    "import pickle as pk\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "### Holdout dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The holdout data\n",
    "data_file = './data/alphaseq_data_hold_out.csv'\n",
    "df = pd.read_csv(data_file)\n",
    "rows1 = df.shape[0]\n",
    "print('holdout dataframe has', rows1, 'rows')\n",
    "print(df.columns.tolist())\n",
    "print(df['sequence_a'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Some plotting functions\n",
    "#\n",
    "def plot_preds_hist(preds_file_path):\n",
    "    preds = pk.load(open(preds_file_path, 'rb'))\n",
    "    print('len(preds):', len(preds))\n",
    "    preds = [p[0] for p in preds]\n",
    "    print('preds[0:10]:', preds[0:10])\n",
    "\n",
    "    # Histogram of predicted values\n",
    "    plt.hist(preds, bins=100)\n",
    "    plt.xlabel('pred Kd (nm)')\n",
    "    plt.ylabel('count')\n",
    "    plt.title('Distribution of pred values on holdout set')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_pred_vs_true(preds_file_path, true_file_path, xlim=(0,5), ylim=(0,5)):\n",
    "    preds = pk.load(open(preds_file_path, 'rb'))\n",
    "    y = pk.load(open(true_file_path, 'rb'))\n",
    "    print('len(preds):', len(preds), ', len(y):', len(y))\n",
    "    preds = [p[0] for p in preds]\n",
    "    y = [a[0] for a in y]\n",
    "\n",
    "    # scatter plot of true vs pred\n",
    "    plt.scatter(y, preds, c =\"blue\")\n",
    "    plt.xlabel('experimental Kd (nm)')\n",
    "    plt.ylabel('predicted Kd (nm)')\n",
    "    plt.title('true vs predicted Kd on validation set')\n",
    "    plt.xlim(xlim)\n",
    "    plt.ylim(ylim)\n",
    "    plt.show()\n",
    "\n",
    "# Some error values\n",
    "def print_errors(preds_file_path, true_file_path):\n",
    "    preds = pk.load(open(preds_file_path, 'rb'))\n",
    "    y = pk.load(open(true_file_path, 'rb'))\n",
    "    print('len(preds):', len(preds), ', len(y):', len(y))\n",
    "    preds = [p[0] for p in preds]\n",
    "    y = [a[0] for a in y]\n",
    "\n",
    "    # RMSE\n",
    "    rmse = math.sqrt(np.mean((np.array(y) - np.array(preds))**2))\n",
    "    print('rmse:', rmse)\n",
    "\n",
    "    # MSE\n",
    "    mse = np.mean((np.array(y) - np.array(preds))**2)\n",
    "    print('mse:', mse)\n",
    "\n",
    "    mse2 = nn.MSELoss()(torch.tensor(preds), torch.tensor(y))\n",
    "    print('mse2:', mse2)\n",
    "\n",
    "    # MAE\n",
    "    mae = np.mean(np.abs(np.array(y) - np.array(preds)))\n",
    "    print('mae:', mae) \n",
    "\n",
    "    # Mean and standard deviation of the error\n",
    "    mean = np.mean(np.array(y) - np.array(preds))\n",
    "    std = np.std(np.array(y) - np.array(preds))\n",
    "    print('Error: mean:', mean, ', std:', std)\n",
    "\n",
    "    # Mean of the absolute percentage error\n",
    "    mape = np.mean(np.abs(np.array(y) - np.array(preds))/np.array(y))\n",
    "    print('mape:', mape)\n",
    "\n",
    "    # Median of the absolute percentage error\n",
    "    mdape = np.median(np.abs(np.array(y) - np.array(preds))/np.array(y))\n",
    "    print('mdape:', mdape)\n",
    "\n",
    "    # PPE10: percentage of time the prediction is within 10 percent of the ground truth\n",
    "    ppe10 = np.mean(np.abs(np.array(y) - np.array(preds))/np.array(y) < 0.1)\n",
    "    print('ppe10:', ppe10)\n",
    "\n",
    "    # PPE20: percentage of time the prediction is within 10 percent of the ground truth\n",
    "    ppe20 = np.mean(np.abs(np.array(y) - np.array(preds))/np.array(y) < 0.2)\n",
    "    print('ppe20:', ppe20)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_file_path = ''\n",
    "plot_preds_hist(pred_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_file_path = './inference_results/mlp_model/cleaned-3/preds_mlp_1714946467.902522.pkl'\n",
    "true_file_path = './inference_results/mlp_model/cleaned-3/y_mlp_1714946467.9027646.pkl'\n",
    "print_errors(pred_file_path, true_file_path)\n",
    "plot_pred_vs_true(pred_file_path, true_file_path, xlim=(0,3.5), ylim=(0,3.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Dense MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_file_path = './inference_results/preds_dense_mlp.pkl'\n",
    "plot_preds_hist(pred_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference on the validation set to compare actual with predicted values\n",
    "pred_file_path = './inference_results/preds_dense_mlp_1714520055.8448465.pkl'\n",
    "true_file_path = './inference_results/y_dense_mlp_1714520055.845317.pkl'\n",
    "plot_pred_vs_true(pred_file_path, true_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Residual MLP Clean-3 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_file_path = ''\n",
    "plot_preds_hist(pred_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference on the validation set to compare actual with predicted values\n",
    "pred_file_path = './inference_results/residual_mlp_model/cleaned-3/preds_residual_mlp_1714945823.4635217.pkl'\n",
    "true_file_path = './inference_results/residual_mlp_model/cleaned-3/y_residual_mlp_1714945823.4637432.pkl'\n",
    "print_errors(pred_file_path, true_file_path)\n",
    "plot_pred_vs_true(pred_file_path, true_file_path, xlim=(0,3.5), ylim=(0,3.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "### Vision Transform Model (VIT)  1-channel Clean-3 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_file_path = ''\n",
    "plot_preds_hist(pred_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference on the validation set to compare actual with predicted values\n",
    "pred_file_path = './inference_results/vit_model/cleaned-3/BW/preds_vit_1714868230.7190938.pkl'\n",
    "true_file_path = './inference_results/vit_model/cleaned-3/BW/y_vit_1714868230.7193077.pkl'\n",
    "print_errors(pred_file_path, true_file_path)\n",
    "plot_pred_vs_true(pred_file_path, true_file_path, xlim=(0,3.5), ylim=(0,3.5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Vision Transformer 3-channel,  Clean-3 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference on the validation set to compare actual with predicted values\n",
    "pred_file_path = './inference_results/vit_model/cleaned-3/BGR/preds_vit_1714883259.9500844.pkl'\n",
    "true_file_path = './inference_results/vit_model/cleaned-3/BGR/y_vit_1714883259.9503129.pkl'\n",
    "print_errors(pred_file_path, true_file_path)\n",
    "plot_pred_vs_true(pred_file_path, true_file_path, xlim=(0,3.5), ylim=(0,3.5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### TFormMLP model with residualMLP regression head. Clean-3 Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_file_path = './inference_results/tform_mlp_model/cleaned-3/preds_tform_mlp_1714915311.9102216.pkl'\n",
    "true_file_path = './inference_results/tform_mlp_model/cleaned-3/y_tform_mlp_1714915311.9104567.pkl'\n",
    "print_errors(pred_file_path, true_file_path)\n",
    "plot_pred_vs_true(pred_file_path, true_file_path, xlim=(0,3.5), ylim=(0,3.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot absolute error vs experimental Kd\n",
    "preds = pk.load(open('./inference_results/tform_mlp_model/cleaned-3/preds_tform_mlp_1714915311.9102216.pkl', 'rb'))\n",
    "truth = pk.load(open('./inference_results/tform_mlp_model/cleaned-3/y_tform_mlp_1714915311.9104567.pkl', 'rb'))\n",
    "\n",
    "# scatter plot of true vs pred\n",
    "plt.scatter(truth, np.abs(np.array(preds)-np.array(truth)), c =\"blue\")\n",
    "plt.xlabel('experimental Kd (nm)')\n",
    "plt.ylabel('absolute error')\n",
    "plt.title('error vs experimental value on validation set')\n",
    "# plt.xlim(xlim)\n",
    "# plt.ylim(ylim)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### t-SNE analysis\n",
    "\n",
    "The transformer-based models should have learned relationships between the elements of the sequence.  See how this appears in t-SNE plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from models.tform_mlp.tform_mlp import TFormMLP_Lightning\n",
    "from datasets.scFv_dataset import scFv_Dataset as dataset\n",
    "import yaml\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# Read the config\n",
    "#----------------------------------------------------------\n",
    "config_path = './config/tform_mlp_params.yaml'  \n",
    "with open(config_path, 'r') as file:\n",
    "    try:\n",
    "        config = yaml.safe_load(file)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n",
    "\n",
    "config = config['model_params']\n",
    "print(config)\n",
    "pl.seed_everything(config['seed'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------\n",
    "# Load the dataset and dataloaders\n",
    "#----------------------------------------------------------\n",
    "test_dataset = dataset(config, config['test_data_path'], regularize=False)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=config['batch_size'])\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# Load pre-trained model\n",
    "#----------------------------------------------------------\n",
    "assert config['checkpoint_name'] != 'None'\n",
    "print('Restarting from checkpoint: ', config['checkpoint_name'])\n",
    "path = config['checkpoint_name']\n",
    "model = TFormMLP_Lightning.load_from_checkpoint(checkpoint_path=path, config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(test_loader)\n",
    "batch = next(it)\n",
    "x, y = batch\n",
    "print('x shape:', x.shape, ', y shape:', y.shape)\n",
    "\n",
    "y_hat, trans_out = model(x.to(model.device))\n",
    "print('y_hat shape:', y_hat.shape, ', trans_out shape', trans_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import repeat\n",
    "\n",
    "print('trans_out shape:', trans_out.shape)\n",
    "b, n, d = trans_out.shape\n",
    "print('b:', b, ', n:', n, ', d:', d)\n",
    "\n",
    "ctx_labels = torch.arange(0, config['block_size']+1)\n",
    "# ctx_labels = ctx_labels.unsqueeze(0).unsqueeze(0)\n",
    "print('ctx_labels shape:', ctx_labels.shape)\n",
    "# print('ctx_labels:', ctx_labels)\n",
    "\n",
    "# blah = repeat(ctx_labels, '() n d -> b n d', b = b)\n",
    "# print('blah shape:', blah.shape)\n",
    "\n",
    "\n",
    "# Three types of tokens to distinguish in the tsne plot:\n",
    "# 1. classifier token (used in the regression)\n",
    "# 2. aa tokens in the CDR region\n",
    "# 3. all others (including the CLS and PAD tokens)\n",
    "ctx_cats = torch.ones_like(ctx_labels)  # label everything like it's a non-CDR aa group\n",
    "ctx_cats[0] = 0  # the classifier token used in regression\n",
    "ctx_cats[1] = 3  # CLS token added when the sequence was constructed\n",
    "ctx_cats[29:109] = 2  # the CDR region is aa residues 29-108\n",
    "\n",
    "print(ctx_cats)\n",
    "\n",
    "labels = ctx_cats.repeat(config['batch_size'])\n",
    "print('labels shape:', labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx_vectors = torch.reshape(trans_out, (trans_out.shape[0]*trans_out.shape[1], trans_out.shape[2]))\n",
    "# ctx_labels = torch.arange(0, config['block_size']).repeat\n",
    "# ctx_labels = torch.reshape(ctx_labels, (ctx_labels.shape[0]*ctx_labels.shape[1], 1))\n",
    "# ctx_labels = ctx_labels.squeeze()\n",
    "# ctx_yhat = torch.repeat_interleave(y_hat, len(dvm_schema.get_column_names_encoded()))\n",
    "# ctx_yhat = ctx_yhat.detach().cpu().numpy()\n",
    "print('ctx_vectors shape', ctx_vectors.shape)\n",
    "# print('ctx_labels shape', ctx_labels.shape)\n",
    "# print('ctx_yhat shape:', ctx_yhat.shape)\n",
    "\n",
    "# print(ctx_vectors[9])\n",
    "# print(ctx_labels[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "n_iter = 10000\n",
    "\n",
    "# 2D\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=config['seed'], metric=\"cosine\", n_iter=n_iter, verbose=True)\n",
    "x_tsne = tsne.fit_transform(ctx_vectors.detach().cpu().numpy())\n",
    "print('x_tsne shape:', x_tsne.shape)\n",
    "print(tsne.kl_divergence_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pk.dump(x_tsne, open('./misc_analysis/tform_mlp/tsne_x_10000iter_tform_mlp.pkl', 'wb'))\n",
    "\n",
    "x_tsne = pk.load(open('./misc_analysis/tform_mlp/tsne_x_10000iter_tform_mlp.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tsne = pd.DataFrame(x_tsne, columns=['tsne_x', 'tsne_y'])\n",
    "# df_tsne['ctx_col_idx'] = ctx_labels\n",
    "# df_tsne['categ_val'] = x_categ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array with the colors you want to use\n",
    "colors = [\"#FF0000\", \"#00FF00\", \"#0000FF\"] # rgb\n",
    "# Set your custom color palette\n",
    "sns.set_palette(sns.color_palette(colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create an array with three colors\n",
    "# colors = [\"#FF0000\", \"#00FF00\", \"#0000FF\", \"#000000\"] # rgb, black\n",
    "colors = [\"#0000FF\", \"#A0A0A0\", \"#FF0000\", \"#000000\"] # rgb, black\n",
    "# Set custom color palette\n",
    "my_palette = sns.color_palette(colors)\n",
    "sns.set_palette(my_palette)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "x_all = x_tsne[:, 0] #df_tsne['tsne_x'].values\n",
    "y_all = x_tsne[:, 1] #df_tsne['tsne_y'].values\n",
    "cat_all = labels     #df_tsne['categ_val'].values\n",
    "plt.title('t-SNE of transformer output tensors')  #category_name\n",
    "ax.set_xlabel(\"t-SNE y\")\n",
    "ax.set_ylabel(\"t-SNE x\")\n",
    "p = sns.scatterplot(x=x_all, y=y_all, alpha=0.6, ax=ax, palette=sns.color_palette(my_palette), hue=labels, legend=True)\n",
    "\n",
    "# title\n",
    "p.legend_.set_title('Token type')\n",
    "new_labels = ['regression token', 'aa: non-CDR', 'aa: CDR region (29-108)', 'CLS token in sequence']\n",
    "for t, l in zip(p.legend_.texts, new_labels):\n",
    "    t.set_text(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the color palette\n",
    "sns.set_palette(sns.color_palette(\"Paired\"))\n",
    "# Plot the data, specifying a different color for data points in\n",
    "# each of the day categories (weekday and weekend)\n",
    "ax = sns.scatterplot(x='day', y='miles_walked', data=dataset, hue='day_category')\n",
    "# Customize the axes and title\n",
    "ax.set_title(\"Miles walked\")\n",
    "ax.set_xlabel(\"day\")\n",
    "ax.set_ylabel(\"total miles\")\n",
    "# Remove top and right borders\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "avm-dvm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
